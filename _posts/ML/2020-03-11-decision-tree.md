---
categories: ML/DL
title: 'Decision Tree'
---


장점 : 해석력 > 모델의 정확성 이외에도 활용성 ( 메세지 ) :: 결과에 대한 풀이 (연속형 - 범주형 등의 형태에 대한 범용성 높음)

단점 : 변동성 / 샘플에의 민감

결과값 > 반응변수 예측하는 형태로 나타남 

- 범주형 변수 - 분류
- 연속형 변수 - 회귀 : 조건을 만족하는 샘플집단의 y의 평균값을 알려줌



### 엔트로피  Entropy

섞여있는 정도 

정의 1. -p(p - 1) + c

정의2. -plog... 



### Information gain

활용한 변수로 인한 이득 // ig로 각 변수를 평가 (outlook / humidity)  > 어떤 변수를 최상위 노드로 사용할지 결정함

- 4개 모두 yes 일 때 : 4/4 > 로그가 0이 됨

- 2/5 > -0.4log2 0.4 - 0.6log2 0.6 
- all : 9 / 14 개 

관측치를 많이 갖고 있음 > 다수의 웨이트를 줌  ( e.g. 전체 14개 중 첫 번째 범주에 5/ 4/ 5 - 가중평균을 구해줌)

섞여있음 ( 엔트로피 높음 ) > 분류 진행 ( 엔트로피 낮춤 )



## Classification Tree

m번째 노드가 k 범주일 확률 : y가 k 범주 안에 존재하면 카운트 - reason을 어떻게 구하는지에 대한 결정 

ig가 최대화 되는 영역

오분류율 : 전체 샘플 개수 내 상대 비율 - 오류율



Rm결정 이후 (특정 변수를 어떤 기준으로 나눌 것인지) 결정된 Rm에 대해 pmk 중 가장 이 값이 커지는 k를 구함 > y범주를 구할 것



## Regression Tree

종속변수가 연속형 - 시각화 시 높이 == 예측값

각각에 대해 특정 실수값을 줌  - cm (z 축) 값을 곱함 

임의로 영역을 나눔 > measure 부분을 엔트로피나 gini index를 사용해 최소화되는 점을 찾음

Cm > 샘플의 평균값 

